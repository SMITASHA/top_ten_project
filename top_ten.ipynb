{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse as UP\n",
    "import yaml\n",
    "import pymongo\n",
    "import bs4\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for chromedriver\n",
    "\n",
    "with open(\"config.yml\", \"r\") as ymlpath:\n",
    "    config = yaml.safe_load(ymlpath)\n",
    "    executable_path = {\"executable_path\": config[\"config-key\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES: For windows, un-comment cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executable_path = {\"executable_path\": \"chromedriver\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Box Office Mojo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_scraper():\n",
    "    \n",
    "    \"\"\"Scrapes www.boxofficemojo.com for the top ten movies for 2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, rank, movie title, and studio\"\"\"\n",
    "    \n",
    "    year = str(2018)\n",
    "    movie_df_list=[]\n",
    "    \n",
    "    # Get webpage data using requests\n",
    "    response = requests.get(\"https://www.boxofficemojo.com/yearly/chart/?view2=worldwide&yr=%s&p=.htm\" % year)\n",
    "    \n",
    "    #Parse HTML using Beautiful Soup\n",
    "    soup = bs(response.text,\"html.parser\")\n",
    "\n",
    "    # Find location of necessary data in soup object\n",
    "    soup_tables = soup.find_all(\"table\")\n",
    "    soup_elements = soup_tables[3].find_all(\"td\")\n",
    "\n",
    "    # For each td element, find and store data in a list \n",
    "    movie_data=[]\n",
    "\n",
    "    for i in soup_elements:\n",
    "        if i.find(\"a\")!=None:\n",
    "            movie_data.append(i.find(\"a\").contents[0]) \n",
    "        elif i.find(\"font\")!=None:\n",
    "            movie_data.append(i.find(\"font\").contents[0])\n",
    "        elif i.find(\"b\")!=None:\n",
    "            movie_dataappend(i.find(\"b\").contents[0])\n",
    "\n",
    "    ### Clean Data:\n",
    "\n",
    "    # Remove extraneous tags\n",
    "    movie_data = [a.contents[0] if type(a)!=bs4.element.NavigableString else a for a in movie_data]\n",
    "\n",
    "    # Strip special characters\n",
    "    movie_data = [re.sub(\"[^A-Za-z0-9-. ]+\", \"\", a) for a in movie_data]\n",
    "\n",
    "    # Fill NaNs\n",
    "    movie_data = [np.nan if a ==\"na\" else a for a in movie_data]\n",
    "\n",
    "    # Set first 6 elements as column headers\n",
    "    to_df = movie_data[6:]\n",
    "\n",
    "    # Define the column names \n",
    "    columns = [\"rank\",\"title\",\"studio\",\"worldwide-gross\",\"domestic-gross\",\"domestic-pct\",\"overseas-gross\",\"overseas-pct\"]\n",
    "\n",
    "    # Convert to dataframe\n",
    "    nrow = int(len(to_df)/len(columns)) \n",
    "    dirty_movies_df = pd.DataFrame(np.array(to_df).reshape(nrow,8),columns=columns)\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    dirty_movies_df = dirty_movies_df.iloc[: , 0:3]\n",
    "    dirty_movies_df[\"rank\"] = dirty_movies_df[\"rank\"].apply(int)\n",
    "    movies_df = dirty_movies_df.loc[dirty_movies_df[\"rank\"] <=10,:]\n",
    "    \n",
    "    # Convert dataframe to list of dictionaries\n",
    "    movie_dicts = movies_df.to_dict(orient=\"records\") \n",
    "    \n",
    "    print(\"Movies Scraped from BoxOfficeMojo.\")\n",
    "    \n",
    "    return (movie_dicts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Scraped from BoxOfficeMojo.\n"
     ]
    }
   ],
   "source": [
    "x = movie_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rank': 1, 'title': 'Avengers Infinity War', 'studio': 'BV'}, {'rank': 2, 'title': 'Black Panther', 'studio': 'BV'}, {'rank': 3, 'title': 'Jurassic World Fallen Kingdom', 'studio': 'Uni.'}, {'rank': 4, 'title': 'Incredibles 2', 'studio': 'BV'}, {'rank': 5, 'title': 'Aquaman', 'studio': 'WB'}, {'rank': 6, 'title': 'Bohemian Rhapsody', 'studio': 'Fox'}, {'rank': 7, 'title': 'Venom 2018', 'studio': 'Sony'}, {'rank': 8, 'title': 'Mission Impossible - Fallout', 'studio': 'Par.'}, {'rank': 9, 'title': 'Deadpool 2', 'studio': 'Fox'}, {'rank': 10, 'title': 'Fantastic Beasts The Crimes of Grindelwald', 'studio': 'WB'}]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Billboard Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chart(data, year):\n",
    "    \n",
    "    \"\"\" Use the Python package for parsing HTML.  Calls and receives HTML as strings to process for artists.\"\"\"\n",
    "    \n",
    "    # Create soup object to parse the html\n",
    "    soup = bs(data,\"html5lib\")\n",
    "    \n",
    "    # Create a list to return\n",
    "    list_albums = []\n",
    "\n",
    "    # Inspect parsed html\n",
    "    # For each article item, loop and identify tags to extract from.\n",
    "    # For each entry, add a dictionary to the album list\n",
    "    \n",
    "    for item in soup.select(\"article\"):\n",
    "        rank = int(item.select_one(\".ye-chart-item__rank\").string.strip())\n",
    "        title = item.select_one(\".ye-chart-item__title\").string.strip()\n",
    "        artist = item.select_one(\".ye-chart-item__artist\").text.replace(\"\\n\", \"\")\n",
    "        list_albums.append({\"rank\":rank, \"title\":title, \"artist\":artist,\"year\":year})\n",
    "    \n",
    "    return(list_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def album_scraper():\n",
    "\n",
    "    \"\"\"Scrapes www.billboard.com for the top ten albums for 2008-2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, album title, and artist name\"\"\"\n",
    "    \n",
    "    year = str(2018)\n",
    "    \n",
    "    all_albums = []\n",
    "\n",
    "    # Use requests library to get HTML\n",
    "    url = requests.get(\"https://www.billboard.com/charts/year-end/\"+str(year)+\"/top-billboard-200-albums\")\n",
    "    \n",
    "    # Parse content and create list of dictionaries using process_chart function\n",
    "    data = url.content\n",
    "    all_albums = process_chart(data,year)\n",
    "    \n",
    "    # Filter just the top 10 albums and insert into final list of dictionaries\n",
    "    album_dicts = []\n",
    "    for album in all_albums:\n",
    "        if (album[\"rank\"] < 11):\n",
    "            album_dicts.append(album)\n",
    "            \n",
    "    print(\"Albums Scraped from Billboard.\")\n",
    "    \n",
    "    return(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albums Scraped from Billboard.\n"
     ]
    }
   ],
   "source": [
    "x = album_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rank': 1, 'title': 'reputation', 'artist': 'Taylor Swift', 'year': '2018'}, {'rank': 2, 'title': 'Scorpion', 'artist': 'Drake', 'year': '2018'}, {'rank': 3, 'title': 'beerbongs & bentleys', 'artist': 'Post Malone', 'year': '2018'}, {'rank': 4, 'title': 'The Greatest Showman', 'artist': 'Soundtrack', 'year': '2018'}, {'rank': 5, 'title': 'รท (Divide)', 'artist': 'Ed Sheeran', 'year': '2018'}, {'rank': 6, 'title': 'Invasion Of Privacy', 'artist': 'Cardi B', 'year': '2018'}, {'rank': 7, 'title': 'ASTROWORLD', 'artist': 'Travis Scott', 'year': '2018'}, {'rank': 8, 'title': 'Stoney', 'artist': 'Post Malone', 'year': '2018'}, {'rank': 9, 'title': '?', 'artist': 'XXXTENTACION', 'year': '2018'}, {'rank': 10, 'title': 'Culture II', 'artist': 'Migos', 'year': '2018'}]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_movie_scraper(url):\n",
    "\n",
    "    \"\"\"Scrapes given metacritic.com url for the movie review information.\n",
    "    Returns a dictionary with number of user reviews, average user review, number of critic reviews, and critic score\"\"\"\n",
    "    \n",
    "    # Use splinter to get website information\n",
    "    with Browser(\"chrome\", **executable_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "        \n",
    "        # Create a timestamp\n",
    "        now = datetime.now()\n",
    "        scrape_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        #Use beautiful soup to parse html\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "\n",
    "    try:\n",
    "        # Find number of reviews from users and critics\n",
    "        rev_count_strings = soup.find_all(\"span\", class_=\"based_on\")\n",
    "        user_rev_count = int(rev_count_strings[1].text.split(\" \")[2])\n",
    "        critic_rev_count = int(rev_count_strings[0].text.split(\" \")[2])\n",
    "\n",
    "        # Find review average from users and rating score from critics\n",
    "        review_soup = soup.find_all(\"a\", class_=\"metascore_anchor\")\n",
    "        user_rev_avg = float(review_soup[1].text)\n",
    "        critic_rev_score = int(review_soup[0].text)\n",
    "\n",
    "    # If page does note have review information, population review information with None values\n",
    "    except (IndexError, AttributeError):\n",
    "        user_rev_count = None\n",
    "        critic_rev_count = None\n",
    "        user_rev_avg = None\n",
    "        critic_rev_score = None    \n",
    "    \n",
    "    # Return dictionary of book information\n",
    "    movie_dict = {\"user_rev_count\": user_rev_count, \"user_rev_avg\": user_rev_avg, \"critic_rev_count\": critic_rev_count, \"critic_rev_score\": critic_rev_score, \"scrape_time\": scrape_time}\n",
    "    return(movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_album_scraper(url):\n",
    "\n",
    "    \"\"\"Scrapes given metacritic.com url for the album review information.\n",
    "    Returns a dictionary with number of user reviews, average user review, number of critic reviews, and critic score\"\"\"\n",
    "    \n",
    "    # Use splinter to get website information\n",
    "    with Browser(\"chrome\", **executable_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "        \n",
    "        # Create a timestamp\n",
    "        now = datetime.now()\n",
    "        scrape_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        #Use beautiful soup to parse html\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # Find review average from users and rating score from critics\n",
    "        review_soup = soup.find_all(\"a\", class_=\"metascore_anchor\")\n",
    "        user_rev_avg = float(review_soup[1].text)\n",
    "        critic_rev_score = int(review_soup[0].text)\n",
    "\n",
    "        # Find number of user reviews\n",
    "        count_soup = soup.find(\"div\",class_=\"module reviews_module user_reviews_module\")\n",
    "        user_rev_count_string = count_soup.find(\"span\",class_=\"count\")\n",
    "        user_rev_count = int(user_rev_count_string.text)\n",
    "\n",
    "        # Find number of critic reviews\n",
    "        critic_rev_count_string = count_soup.find(\"span\",class_=\"count\")\n",
    "        critic_rev_count = int(critic_rev_count_string.text)\n",
    "    \n",
    "    # If page does note have review information, population review information with None values\n",
    "    except (IndexError, AttributeError) :\n",
    "        user_rev_count = None\n",
    "        critic_rev_count = None\n",
    "        user_rev_avg = None\n",
    "        critic_rev_score = None\n",
    "\n",
    "    # Return dictionary of album information\n",
    "    album_dict = {\"user_rev_count\": user_rev_count, \"user_rev_avg\": user_rev_avg, \"critic_rev_count\": critic_rev_count, \"critic_rev_score\": critic_rev_score, \"scrape_time\": scrape_time}\n",
    "  \n",
    "    return (album_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url_string(string):\n",
    "    \"\"\"Takes a string and returns a string to be inserted in url\"\"\"\n",
    "    \n",
    "    url_string = string.replace(\"(\", \"\").replace(\")\",\"\").replace(\"รท\", \"\").replace(\"&\", \"\").replace(\"-\", \"\").\\\n",
    "    replace(\"  \", \" \").replace(\" \", \"-\").lower()\n",
    "    \n",
    "    if url_string.startswith(\"-\"):\n",
    "        url_string = url_string[1:]\n",
    "    \n",
    "    if url_string.endswith(\"-\"):\n",
    "        url_string = url_string[: -1]\n",
    "\n",
    "    return(url_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of dictionaries for top movies and music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Scraped from BoxOfficeMojo.\n",
      "Albums Scraped from Billboard.\n"
     ]
    }
   ],
   "source": [
    "# Scrape BoxOfficeMojo and Billboard Music for a list of dictionaries of the top 10 movies for 2008-2018\n",
    "movie_BOM_dicts = movie_scraper()\n",
    "album_Bill_dicts = album_scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change x to be 0-9\n",
    "x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = movie_BOM_dicts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Panther scraped\n"
     ]
    }
   ],
   "source": [
    "movie_dicts = []\n",
    "# Create query url from dictionary values\n",
    "movie_query = make_url_string(movie[\"title\"])\n",
    "movie_url = f\"https://www.metacritic.com/movie/{movie_query}/details\"\n",
    "\n",
    "# Add review information to dictionary\n",
    "movie_dicts.append({**movie, **metacritic_movie_scraper(movie_url)})\n",
    "print(f\"{movie['title']} scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rank': 2, 'title': 'Black Panther', 'studio': 'BV', 'user_rev_count': 2829, 'user_rev_avg': 6.5, 'critic_rev_count': 55, 'critic_rev_score': 88, 'scrape_time': '2019-05-06 08:26:15'}]\n"
     ]
    }
   ],
   "source": [
    "print(movie_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALBUM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change x to be 0-9\n",
    "x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "album = album_Bill_dicts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorpion scraped\n"
     ]
    }
   ],
   "source": [
    "album_dicts = []\n",
    "# Create query url from dictionary values\n",
    "title_query = make_url_string(album[\"title\"])\n",
    "artist_query = make_url_string(album[\"artist\"])\n",
    "album_url = f\"https://www.metacritic.com/music/{title_query}/{artist_query}\"\n",
    "\n",
    "# Add review information to dictionary\n",
    "album_dicts.append({**album, **metacritic_album_scraper(album_url)})\n",
    "print(f\"{album['title']} scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rank': 2, 'title': 'Scorpion', 'artist': 'Drake', 'year': '2018', 'user_rev_count': 34, 'user_rev_avg': 3.8, 'critic_rev_count': 34, 'critic_rev_score': 67, 'scrape_time': '2019-05-06 08:29:02'}]\n"
     ]
    }
   ],
   "source": [
    "print(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers Infinity War scraped\n",
      "Black Panther scraped\n",
      "Jurassic World Fallen Kingdom scraped\n",
      "Incredibles 2 scraped\n",
      "Aquaman scraped\n",
      "Bohemian Rhapsody scraped\n",
      "Venom 2018 scraped\n",
      "Mission Impossible - Fallout scraped\n",
      "Deadpool 2 scraped\n",
      "Fantastic Beasts The Crimes of Grindelwald scraped\n",
      "reputation scraped\n",
      "Scorpion scraped\n",
      "beerbongs & bentleys scraped\n",
      "The Greatest Showman scraped\n",
      "รท (Divide) scraped\n",
      "Invasion Of Privacy scraped\n",
      "ASTROWORLD scraped\n",
      "Stoney scraped\n",
      "? scraped\n",
      "Culture II scraped\n"
     ]
    }
   ],
   "source": [
    "# Add review information from Metacritic to new list of dictionaries for top movies\n",
    "movie_dicts = []\n",
    "for movie in movie_BOM_dicts:\n",
    "    \n",
    "    # Create query url from dictionary values\n",
    "    movie_query = make_url_string(movie[\"title\"])\n",
    "    movie_url = f\"https://www.metacritic.com/movie/{movie_query}/details\"\n",
    "\n",
    "    # Add review information to dictionary\n",
    "    movie_dicts.append({**movie, **metacritic_movie_scraper(movie_url)})\n",
    "    print(f\"{movie['title']} scraped\")\n",
    "    \n",
    "# Add review information from Metacritic to new list of dictionaries for top music albums\n",
    "album_dicts = []\n",
    "for album in album_Bill_dicts:\n",
    "    # Create query url from dictionary values\n",
    "    title_query = make_url_string(album[\"title\"])\n",
    "    artist_query = make_url_string(album[\"artist\"])\n",
    "    album_url = f\"https://www.metacritic.com/music/{title_query}/{artist_query}\"\n",
    "    \n",
    "    # Add review information to dictionary\n",
    "    album_dicts.append({**album, **metacritic_album_scraper(album_url)})\n",
    "    print(f\"{album['title']} scraped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x120968b08>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to mongo using pymongo to create local database\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Create Top 10 database\n",
    "db = client.top_10_db\n",
    "\n",
    "# Create movies and albums collections\n",
    "movies = db.movies\n",
    "albums = db.albums\n",
    "\n",
    "# Insert top 10 movies and albums for 2008-2018\n",
    "# GRETEL - FIGURE OUT WHETHER WE WANT TO UPSERT\n",
    "db.movies.insert_many(movie_dicts)\n",
    "db.albums.insert_many(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
