{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse as UP\n",
    "import yaml\n",
    "import pymongo\n",
    "import bs4\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for chromedriver\n",
    "\n",
    "with open(\"config.yml\", \"r\") as ymlpath:\n",
    "    config = yaml.safe_load(ymlpath)\n",
    "    executable_path = {\"executable_path\": config[\"config-key\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES: For windows, un-comment cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executable_path = {\"executable_path\": \"chromedriver\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Box Office Mojo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_scraper(year):\n",
    "    \n",
    "    \"\"\"Scrapes www.boxofficemojo.com for the top ten movies for 2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, rank, movie title, and studio\"\"\"\n",
    "    \n",
    "    movie_df_list=[]\n",
    "    \n",
    "    # Get webpage data using requests\n",
    "    response = requests.get(\"https://www.boxofficemojo.com/yearly/chart/?view2=worldwide&yr=%s&p=.htm\" % year)\n",
    "    \n",
    "    #Parse HTML using Beautiful Soup\n",
    "    soup = bs(response.text,\"html.parser\")\n",
    "\n",
    "    # Find location of necessary data in soup object\n",
    "    soup_tables = soup.find_all(\"table\")\n",
    "    soup_elements = soup_tables[3].find_all(\"td\")\n",
    "\n",
    "    # For each td element, find and store data in a list \n",
    "    movie_data=[]\n",
    "\n",
    "    for i in soup_elements:\n",
    "        if i.find(\"a\")!=None:\n",
    "            movie_data.append(i.find(\"a\").contents[0]) \n",
    "        elif i.find(\"font\")!=None:\n",
    "            movie_data.append(i.find(\"font\").contents[0])\n",
    "        elif i.find(\"b\")!=None:\n",
    "            movie_dataappend(i.find(\"b\").contents[0])\n",
    "\n",
    "    ### Clean Data:\n",
    "\n",
    "    # Remove extraneous tags\n",
    "    movie_data = [a.contents[0] if type(a)!=bs4.element.NavigableString else a for a in movie_data]\n",
    "\n",
    "    # Strip special characters\n",
    "    movie_data = [re.sub(\"[^A-Za-z0-9-. ]+\", \"\", a) for a in movie_data]\n",
    "\n",
    "    # Fill NaNs\n",
    "    movie_data = [np.nan if a ==\"na\" else a for a in movie_data]\n",
    "\n",
    "    # Set first 6 elements as column headers\n",
    "    to_df = movie_data[6:]\n",
    "\n",
    "    # Define the column names \n",
    "    columns = [\"rank\",\"title\",\"studio\",\"worldwide-gross\",\"domestic-gross\",\"domestic-pct\",\"overseas-gross\",\"overseas-pct\"]\n",
    "\n",
    "    # Convert to dataframe\n",
    "    nrow = int(len(to_df)/len(columns)) \n",
    "    dirty_movies_df = pd.DataFrame(np.array(to_df).reshape(nrow,8),columns=columns)\n",
    "    \n",
    "    # Add year to dataframe\n",
    "    dirty_movies_df[\"year\"] = year\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    dirty_movies_df = dirty_movies_df.iloc[: , 0:3]\n",
    "    dirty_movies_df[\"rank\"] = dirty_movies_df[\"rank\"].apply(int)\n",
    "    movies_df = dirty_movies_df.loc[dirty_movies_df[\"rank\"] <=10,:]\n",
    "    \n",
    "    # Convert dataframe to list of dictionaries\n",
    "    movie_dicts = movies_df.to_dict(orient=\"records\") \n",
    "    \n",
    "    print(\"Movies Scraped from BoxOfficeMojo.\")\n",
    "    \n",
    "    return (movie_dicts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enter 2008-2018 for year\n",
    "# year = 2008\n",
    "# x = movie_scraper(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Billboard Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chart(data, year):\n",
    "    \n",
    "    \"\"\" Use the Python package for parsing HTML.  Calls and receives HTML as strings to process for artists.\"\"\"\n",
    "    \n",
    "    # Create soup object to parse the html\n",
    "    soup = bs(data,\"html5lib\")\n",
    "    \n",
    "    # Create a list to return\n",
    "    list_albums = []\n",
    "\n",
    "    # Inspect parsed html\n",
    "    # For each article item, loop and identify tags to extract from.\n",
    "    # For each entry, add a dictionary to the album list\n",
    "    \n",
    "    for item in soup.select(\"article\"):\n",
    "        rank = int(item.select_one(\".ye-chart-item__rank\").string.strip())\n",
    "        title = item.select_one(\".ye-chart-item__title\").string.strip()\n",
    "        artist = item.select_one(\".ye-chart-item__artist\").text.replace(\"\\n\", \"\")\n",
    "        list_albums.append({\"rank\":rank, \"title\":title, \"artist\":artist,\"year\":year})\n",
    "    \n",
    "    return(list_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def album_scraper(year):\n",
    "\n",
    "    \"\"\"Scrapes www.billboard.com for the top ten albums for 2008-2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, album title, and artist name\"\"\"\n",
    "    \n",
    "    all_albums = []\n",
    "\n",
    "    # Use requests library to get HTML\n",
    "    url = requests.get(\"https://www.billboard.com/charts/year-end/\"+str(year)+\"/top-billboard-200-albums\")\n",
    "    \n",
    "    # Parse content and create list of dictionaries using process_chart function\n",
    "    data = url.content\n",
    "    all_albums = process_chart(data,year)\n",
    "    \n",
    "    # Filter just the top 10 albums and insert into final list of dictionaries\n",
    "    album_dicts = []\n",
    "    for album in all_albums:\n",
    "        if (album[\"rank\"] < 11):\n",
    "            album_dicts.append(album)\n",
    "            \n",
    "    print(\"Albums Scraped from Billboard.\")\n",
    "    \n",
    "    return(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enter year 2008-2018\n",
    "# year = 2008\n",
    "# x = album_scraper(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_movie_scraper(url):\n",
    "\n",
    "    \"\"\"Scrapes given metacritic.com url for the movie review information.\n",
    "    Returns a dictionary with number of user reviews, average user review, number of critic reviews, and critic score\"\"\"\n",
    "    \n",
    "    # Use splinter to get website information\n",
    "    with Browser(\"chrome\", **executable_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "        \n",
    "        # Create a timestamp\n",
    "        now = datetime.now()\n",
    "        scrape_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        #Use beautiful soup to parse html\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "\n",
    "    try:\n",
    "        # Find number of reviews from users and critics\n",
    "        rev_count_strings = soup.find_all(\"span\", class_=\"based_on\")\n",
    "        user_rev_count = int(rev_count_strings[1].text.split(\" \")[2])\n",
    "        critic_rev_count = int(rev_count_strings[0].text.split(\" \")[2])\n",
    "\n",
    "        # Find review average from users and rating score from critics\n",
    "        review_soup = soup.find_all(\"a\", class_=\"metascore_anchor\")\n",
    "        user_rev_avg = float(review_soup[1].text)\n",
    "        critic_rev_score = int(review_soup[0].text)\n",
    "\n",
    "    # If page does note have review information, population review information with None values\n",
    "    except (IndexError, AttributeError):\n",
    "        user_rev_count = None\n",
    "        critic_rev_count = None\n",
    "        user_rev_avg = None\n",
    "        critic_rev_score = None    \n",
    "    \n",
    "    # Return dictionary of book information\n",
    "    movie_dict = {\"user_rev_count\": user_rev_count, \"user_rev_avg\": user_rev_avg, \"critic_rev_count\": critic_rev_count, \"critic_rev_score\": critic_rev_score, \"scrape_time\": scrape_time}\n",
    "    return(movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_album_scraper(url):\n",
    "\n",
    "    \"\"\"Scrapes given metacritic.com url for the album review information.\n",
    "    Returns a dictionary with number of user reviews, average user review, number of critic reviews, and critic score\"\"\"\n",
    "    \n",
    "    # Use splinter to get website information\n",
    "    with Browser(\"chrome\", **executable_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "        \n",
    "        # Create a timestamp\n",
    "        now = datetime.now()\n",
    "        scrape_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        #Use beautiful soup to parse html\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # Find review average from users and rating score from critics\n",
    "        review_soup = soup.find_all(\"a\", class_=\"metascore_anchor\")\n",
    "        user_rev_avg = float(review_soup[1].text)\n",
    "        critic_rev_score = int(review_soup[0].text)\n",
    "\n",
    "        # Find number of user reviews\n",
    "        count_soup = soup.find(\"div\",class_=\"module reviews_module user_reviews_module\")\n",
    "        user_rev_count_string = count_soup.find(\"span\",class_=\"count\")\n",
    "        user_rev_count = int(user_rev_count_string.text)\n",
    "\n",
    "        # Find number of critic reviews\n",
    "        critic_rev_count_string = count_soup.find(\"span\",class_=\"count\")\n",
    "        critic_rev_count = int(critic_rev_count_string.text)\n",
    "    \n",
    "    # If page does note have review information, population review information with None values\n",
    "    except (IndexError, AttributeError) :\n",
    "        user_rev_count = None\n",
    "        critic_rev_count = None\n",
    "        user_rev_avg = None\n",
    "        critic_rev_score = None\n",
    "\n",
    "    # Return dictionary of album information\n",
    "    album_dict = {\"user_rev_count\": user_rev_count, \"user_rev_avg\": user_rev_avg, \"critic_rev_count\": critic_rev_count, \"critic_rev_score\": critic_rev_score, \"scrape_time\": scrape_time}\n",
    "  \n",
    "    return (album_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url_string(string):\n",
    "    \"\"\"Takes a string and returns a string to be inserted in url\"\"\"\n",
    "    \n",
    "    url_string = string.replace(\"(\", \"\").replace(\")\",\"\").replace(\"÷\", \"\").replace(\"&\", \"\").replace(\"-\", \"\").\\\n",
    "    replace(\"  \", \" \").replace(\" \", \"-\").lower()\n",
    "    \n",
    "    if url_string.startswith(\"-\"):\n",
    "        url_string = url_string[1:]\n",
    "    \n",
    "    if url_string.endswith(\"-\"):\n",
    "        url_string = url_string[: -1]\n",
    "\n",
    "    return(url_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_year(year):\n",
    "    \n",
    "    \"\"\"Takes a string \"year\" as a parameter. Returns boolean True if it is a valid year from 2008-2018.\n",
    "    Prints error message and returns boolean False if it is not.\"\"\"\n",
    "    \n",
    "    if (str.isdigit(year) is False):\n",
    "        print(f\"Oops! {year} is not a number!\")\n",
    "        return(False)\n",
    "    elif (int(year)<2008 or int(year)>2018):\n",
    "        print(f\"Oops! {year} is not a year between 2008-2018!\")\n",
    "        return(False)\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_query():\n",
    "    \"\"\"Queries user for year they would like to scrape\"\"\"\n",
    "\n",
    "    year = (input(\"Please enter the year from 2008-2018 you would like to get data for: \"))\n",
    "\n",
    "    # Check to make sure year is valid\n",
    "    while(valid_year(year) is False):\n",
    "        year = (input(\"Please enter the year from 2008-2018 you would like to get data for: \"))\n",
    "\n",
    "    year = int(year)\n",
    "    return(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS THE MAIN FUNCTION\n",
    "\n",
    "## Run below multiple times\n",
    "## Try entering non-number years, years out of range, years you have already gotten numbers for\n",
    "## After running for year(s) within appropriate range, do an audit by randomly checking the data points using mongo compass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CURRENTLY, THIS DOES NOT WORK FOR THE YEAR 2012. IT IS AN ISSUE WITH ALBUM SCRAPER FOR AN ALBUM IN THE BILLBOARD DATABASE\n",
    "\n",
    "I think it's an error for 'title': 'Christmas', 'artist': 'Michael Buble'\n",
    "\n",
    "critic_rev_score = int(review_soup[0].text) threw the following error:\n",
    "    ValueError: invalid literal for int() with base 10: '\\n7.7\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the year from 2008-2018 you would like to get data for: 2007\n",
      "Oops! 2007 is not a year between 2008-2018!\n",
      "Please enter the year from 2008-2018 you would like to get data for: 2009\n",
      "Data already scraped for 2009.\n",
      "Please enter the year from 2008-2018 you would like to get data for: 2010\n",
      "Data already scraped for 2010.\n",
      "Please enter the year from 2008-2018 you would like to get data for: 2011\n",
      "Data already scraped for 2011.\n",
      "Please enter the year from 2008-2018 you would like to get data for: 2012\n",
      "Scraping data for year 2012...\n",
      "Movies Scraped from BoxOfficeMojo.\n",
      "Albums Scraped from Billboard.\n",
      "Marvels The Avengers scraped\n",
      "Skyfall scraped\n",
      "The Dark Knight Rises scraped\n",
      "The Hobbit An Unexpected Journey scraped\n",
      "Ice Age Continental Drift scraped\n",
      "The Twilight Saga Breaking Dawn Part 2 scraped\n",
      "The Amazing Spider-Man scraped\n",
      "Madagascar 3 Europes Most Wanted scraped\n",
      "The Hunger Games scraped\n",
      "MIB 3 scraped\n",
      "21 scraped\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '\\n7.7\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-991e10b62fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Add review information to dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0malbum_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0malbum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmetacritic_album_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbum_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{album['title']} scraped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-75c18939247b>\u001b[0m in \u001b[0;36mmetacritic_album_scraper\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreview_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"metascore_anchor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0muser_rev_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_soup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcritic_rev_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_soup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Find number of user reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '\\n7.7\\n'"
     ]
    }
   ],
   "source": [
    "### Main Function\n",
    "\n",
    "# Connect to mongo using pymongo to create local database\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Connect to Top 10 database\n",
    "db = client.top_10_db\n",
    "\n",
    "# Connect to movies and albums collection\n",
    "movies = db.movies\n",
    "albums = db.albums\n",
    "\n",
    "# Query user for year they would like to get data for\n",
    "year = user_query()\n",
    "\n",
    "# Check to see if year has already been scraped\n",
    "movie_doc = db.movies.find_one({\"year\": year})\n",
    "while (movie_doc != None):\n",
    "    print(f\"Data already scraped for {year}.\")\n",
    "    year = user_query()\n",
    "    movie_doc = db.movies.find_one({\"year\": year})\n",
    "\n",
    "print(f\"Scraping data for year {year}...\")\n",
    "\n",
    "# Scrape BoxOfficeMojo and Billboard Music for a list of dictionaries of the top 10 movies for 2008-2018\n",
    "movie_BOM_dicts = movie_scraper(year)\n",
    "album_Bill_dicts = album_scraper(year)\n",
    "    \n",
    "# Add review information from Metacritic to new list of dictionaries for top movies\n",
    "movie_dicts = []\n",
    "for movie in movie_BOM_dicts:\n",
    "    \n",
    "    # Create query url from dictionary values\n",
    "    movie_query = make_url_string(movie[\"title\"])\n",
    "    movie_url = f\"https://www.metacritic.com/movie/{movie_query}/details\"\n",
    "\n",
    "    # Add review information to dictionary\n",
    "    movie_dicts.append({**movie, **metacritic_movie_scraper(movie_url)})\n",
    "    print(f\"{movie['title']} scraped.\")\n",
    "    \n",
    "# Add review information from Metacritic to new list of dictionaries for top music albums\n",
    "album_dicts = []\n",
    "for album in album_Bill_dicts:\n",
    "    # Create query url from dictionary values\n",
    "    title_query = make_url_string(album[\"title\"])\n",
    "    artist_query = make_url_string(album[\"artist\"])\n",
    "    album_url = f\"https://www.metacritic.com/music/{title_query}/{artist_query}\"\n",
    "    \n",
    "    # Add review information to dictionary\n",
    "    album_dicts.append({**album, **metacritic_album_scraper(album_url)})\n",
    "    print(f\"{album['title']} scraped.\")\n",
    "\n",
    "# Insert movies and albums into database\n",
    "movies = db.movies.insert_many(movie_dicts)\n",
    "print(f\"Movies for {year} entered into database.\")\n",
    "albums = db.albums.insert_many(album_dicts)\n",
    "print(f\"Albums for {year} entered into database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': 2, 'title': 'Christmas', 'artist': 'Michael Buble', 'year': 2012}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_Bill_dicts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TESTING PURPOSES- REMOVE BEFORE FINAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change x to be 0-9\n",
    "# x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie = movie_BOM_dicts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_dicts = []\n",
    "# # Create query url from dictionary values\n",
    "# movie_query = make_url_string(movie[\"title\"])\n",
    "# movie_url = f\"https://www.metacritic.com/movie/{movie_query}/details\"\n",
    "\n",
    "# # Add review information to dictionary\n",
    "# movie_dicts.append({**movie, **metacritic_movie_scraper(movie_url)})\n",
    "# print(f\"{movie['title']} scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(movie_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALBUM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change x to be 0-9\n",
    "# x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# album = album_Bill_dicts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# album_dicts = []\n",
    "# # Create query url from dictionary values\n",
    "# title_query = make_url_string(album[\"title\"])\n",
    "# artist_query = make_url_string(album[\"artist\"])\n",
    "# album_url = f\"https://www.metacritic.com/music/{title_query}/{artist_query}\"\n",
    "\n",
    "# # Add review information to dictionary\n",
    "# album_dicts.append({**album, **metacritic_album_scraper(album_url)})\n",
    "# print(f\"{album['title']} scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add review information from Metacritic to new list of dictionaries for top movies\n",
    "# movie_dicts = []\n",
    "# for movie in movie_BOM_dicts:\n",
    "    \n",
    "#     # Create query url from dictionary values\n",
    "#     movie_query = make_url_string(movie[\"title\"])\n",
    "#     movie_url = f\"https://www.metacritic.com/movie/{movie_query}/details\"\n",
    "\n",
    "#     # Add review information to dictionary\n",
    "#     movie_dicts.append({**movie, **metacritic_movie_scraper(movie_url)})\n",
    "#     print(f\"{movie['title']} scraped\")\n",
    "    \n",
    "# # Add review information from Metacritic to new list of dictionaries for top music albums\n",
    "# album_dicts = []\n",
    "# for album in album_Bill_dicts:\n",
    "#     # Create query url from dictionary values\n",
    "#     title_query = make_url_string(album[\"title\"])\n",
    "#     artist_query = make_url_string(album[\"artist\"])\n",
    "#     album_url = f\"https://www.metacritic.com/music/{title_query}/{artist_query}\"\n",
    "    \n",
    "#     # Add review information to dictionary\n",
    "#     album_dicts.append({**album, **metacritic_album_scraper(album_url)})\n",
    "#     print(f\"{album['title']} scraped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert movies and albums into database\n",
    "# movies = db.movies.insert_many(movie_dicts)\n",
    "# albums = db.albums.insert_many(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
