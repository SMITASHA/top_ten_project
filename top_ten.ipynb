{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.parse as UP\n",
    "import yaml\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for chromedriver\n",
    "\n",
    "with open(\"config.yml\", 'r') as ymlpath:\n",
    "    config = yaml.safe_load(ymlpath)\n",
    "    executable_path = {\"executable_path\": config[\"config-key\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Box Office Mojo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_scraper():\n",
    "    years=[str(a) for a in range(2008,2019)]\n",
    "    df_list=[]\n",
    "    for year in years:\n",
    "        r=rq.get('https://www.boxofficemojo.com/yearly/chart/?view2=worldwide&yr=%s&p=.htm' % year)\n",
    "        print('Box Office data for %s scraped' % year)\n",
    "        p=BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "        ### Look for the table ### \n",
    "        b=p.find_all('table')\n",
    "\n",
    "        ### Usually the fourth table object on page ### \n",
    "        tb=b[3].find_all('td')\n",
    "\n",
    "        ## Each data field is found in a <td> element in the fourth table. Store all data in a list ## \n",
    "        data=[]\n",
    "        for i in tb:\n",
    "            if i.find('a')!=None:\n",
    "                data.append(i.find('a').contents[0])\n",
    "            elif i.find('font')!=None:\n",
    "                 data.append(i.find('font').contents[0])\n",
    "            elif i.find('b')!=None:\n",
    "                data.append(i.find('b').contents[0])\n",
    "\n",
    "        ### Still a <b> tag left for <font> tags ## \n",
    "        data=[a.contents[0] if type(a)!=bs4.element.NavigableString else a for a in data]\n",
    "\n",
    "        ### Strip special characters ### \n",
    "        data=[re.sub('[^A-Za-z0-9-. ]+', '', a) for a in data]\n",
    "\n",
    "        ### Fill NaNs ### \n",
    "        data=[np.nan if a =='na' else a for a in data]\n",
    "\n",
    "        ### Define the feature names ###\n",
    "        columns=['bo_year_rank','title','studio','worldwide-gross','domestic-gross','domestic-pct','overseas-gross','overseas-pct']\n",
    "\n",
    "        ### First 6 elements are column headers # \n",
    "        to_df=data[6:]\n",
    "\n",
    "        ### Escape clause in case the layout changes from year to year ### \n",
    "        if len(to_df)%len(columns) != 0:\n",
    "            print('Possible table misalignment in table for year %s' % year)\n",
    "            break \n",
    "\n",
    "        ### Convert to pandas dataframe ### \n",
    "\n",
    "        nrow=int(len(to_df)/len(columns))\n",
    "        df=pd.DataFrame(np.array(to_df).reshape(nrow,8),columns=columns)\n",
    "        df['bo_year']=int(year)\n",
    "        df_list.append(df)\n",
    "\n",
    "    dirtymovies_df=pd.concat(df_list)\n",
    "    \n",
    "    dirtymovies_df = dirtymovies_df.iloc[: , [0, 1, 2, 8]]\n",
    "    dirtymovies_df[\"bo_year_rank\"] = dirtymovies_df[\"bo_year_rank\"].apply(int)\n",
    "    movies_df = dirtymovies_df.loc[dirtymovies_df[\"bo_year_rank\"] <=10,:]\n",
    "    \n",
    "    Moviedictionary = movies_df.to_dict(orient='records') \n",
    "    \n",
    "    return (Moviedictionary) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Billboard Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def album_scraper():\n",
    "\n",
    "    \"\"\"Scrapes https://www.billboard for the top ten albums for 2008-2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, rank, album name, and artist name\"\"\"\n",
    "    \n",
    "    #Declare Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import jinja2\n",
    "import requests\n",
    "import pymongo\n",
    "from datetime import datetime\n",
    "\n",
    "#Setting variable for time\n",
    "current_time = datetime.now()\n",
    "\n",
    "#Inspect Billboard web.  Capture specific years and albums as lists.\n",
    "years = [2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018]\n",
    "all_albums = []\n",
    "all_albums_objects = []\n",
    "\n",
    "#Use the Python package for parsing HTML.  Calls and receives HTML as strings to process for artists.\n",
    "def process_chart(htmldata, year):\n",
    "    soup = BeautifulSoup(data,\"html5lib\")\n",
    "    list_albums = []\n",
    "\n",
    "#Inspect document and for each item in article loop and identify tags to extract from.\n",
    "    for item in soup.select('article'):\n",
    "        rank = item.select_one(\".ye-chart-item__rank\").string.strip()\n",
    "        image = item.select_one(\".ye-chart-item__image\").find(\"img\").get(\"src\")\n",
    "        title = item.select_one(\".ye-chart-item__title\").string.strip()\n",
    "        artist = item.select_one(\".ye-chart-item__artist\").text\n",
    "        list_albums.append({'rank':rank,'image':image,'artist':artist,'title':title, 'year':year, 'current_time':current_time})\n",
    "        all_albums_objects.append({'rank':rank,'image':image,'artist':artist,'title':title, 'year':year, 'current_time':current_time})\n",
    "    \n",
    "    return list_albums\n",
    "\n",
    "#For each item in the Year list, loop thru, append to url and create records by year   \n",
    "for year in years:\n",
    "\n",
    "    url = requests.get(\"https://www.billboard.com/charts/year-end/\"+str(year)+\"/top-billboard-200-albums\")\n",
    "    data = url.content\n",
    "    all_albums.append(process_chart(data,year))\n",
    "    print (all_albums)\n",
    "    \n",
    "top_ten = []\n",
    "for rank10 in all_albums_objects:\n",
    "   if int(rank10.get(\"rank\")) < 11:\n",
    "       top_ten.append(rank10)\n",
    "\n",
    "x = mycol.insert_many(top_ten)\n",
    "\n",
    "   # return(album_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_movie_scraper(movie_dict):\n",
    "\n",
    "    \"\"\"Adds review information from metacritic.com to provided movie dictionary\n",
    "    Returns a dictionary with year, rank, movie title, user rating, and number of reviewers\"\"\"\n",
    "    \n",
    "    ## INSERT CODE HERE\n",
    "    ## GRETEL - MAKE SURE TO REMOVE THE EXECUTABLE PATH ASSIGNMENT\n",
    "    \n",
    "    return(meta_movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_album_scraper(album_dict):\n",
    "\n",
    "    \"\"\"Adds review information from metacritic.com to provided album dictionary\n",
    "    Returns a dictionary with year, rank, album title, artist name, user rating, and number of reviewers\"\"\"\n",
    "    \n",
    "    ## INSERT CODE HERE\n",
    "    ## GRETEL - MAKE SURE TO REMOVE THE EXECUTABLE PATH ASSIGNMENT\n",
    "    \n",
    "    return(meta_album_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_song_scraper(song_dict):\n",
    "\n",
    "    \"\"\"Adds review information from metacritic.com to provided song dictionary\n",
    "    Returns a dictionary with year, rank, song title, artist name, user rating, and number of reviewers\"\"\"\n",
    "    \n",
    "    ## INSERT CODE HERE\n",
    "    ## GRETEL - MAKE SURE TO REMOVE THE EXECUTABLE PATH ASSIGNMENT\n",
    "    \n",
    "    return(meta_song_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of dictionaries for top movies and music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_list and movie_list, both lists of dictionary, to enter into mongo database\n",
    "# GRETEL - FIGURE OUT EXACTLY HOW THIS WORKS BASED ON WHAT IS RETURNED AT WHAT POINT\n",
    "# IT WOULD BE IDEAL FOR US TO END UP WITH A LIST OF DICTIONARIES FOR EACH MOVIE_DICT_LIST AND MUSIC_DICT_LIST\n",
    "\n",
    "## UPDATE CODE AS APPROPRIATE BASED ON SOURCE CODE FROM OTHER SCRIPTS\n",
    "\n",
    "# Scrape BoxOfficeMojo and Billboard Music for a list of dictionaries of the top 10 movies for 2008-2018\n",
    "movie_BOM_dict_list = movie_scraper()\n",
    "album_Bill_dict_list = album_scraper()\n",
    "song_Bill_dict_list = song_scraper()\n",
    "\n",
    "\n",
    "# Add review information from Metacritic to new list of dictionaries for top movies\n",
    "movie_dict_list = []\n",
    "for movie_dict in movie_BOM_dict_list:\n",
    "    movie_dict_list.append(metacritic_movie_scraper(movie_dict))\n",
    "\n",
    "# Add review information from Metacritic to new list of dictionaries for top music albums\n",
    "album_dict_list = []\n",
    "for album_dict in album_Bill_dict_list:\n",
    "    album_dict_list.append(metacritic_music_scraper(album_dict))\n",
    "    \n",
    "# Add review information from Metacritic to new list of dictionaries for top songs\n",
    "song_dict_list = []\n",
    "for song_dict in song_Bill_dict_list:\n",
    "    song_dict_list.append(metacritic_song_scraper(song_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to mongo using pymongo to create local database\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Create Top 10 database\n",
    "db = client.top_10_db\n",
    "\n",
    "# Create movies, albums, and songs collections\n",
    "movies = db.movies\n",
    "albums = db.albums\n",
    "songs = db.songs\n",
    "\n",
    "# Insert top 10 movies, albums, and songs for 2008-2018\n",
    "# GRETEL - FIGURE OUT WHETHER WE WANT TO UPSERT\n",
    "db.movies.insert_many(movie_dict_list)\n",
    "db.albums.insert_many(album_dict_list)\n",
    "db.songs.insert_many(song_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
