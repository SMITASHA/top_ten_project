{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse as UP\n",
    "import yaml\n",
    "import pymongo\n",
    "import bs4\n",
    "import re\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for chromedriver\n",
    "\n",
    "with open(\"config.yml\", 'r') as ymlpath:\n",
    "    config = yaml.safe_load(ymlpath)\n",
    "    executable_path = {\"executable_path\": config[\"config-key\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Box Office Mojo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_scraper():\n",
    "    \n",
    "    \"\"\"Scrapes https://www.boxofficemojo.com for the top ten movies for 2008-2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, rank, movie title, and studio\"\"\"\n",
    "    \n",
    "    # Create a list of year we are querying data for\n",
    "    years = [str(a) for a in range(2008,2019)]\n",
    "    \n",
    "    movie_df_list=[]\n",
    "    \n",
    "    for year in years:\n",
    "        \n",
    "        # Get webpage data using requests and parse html by creating a beautiful soup object\n",
    "        response = requests.get('https://www.boxofficemojo.com/yearly/chart/?view2=worldwide&yr=%s&p=.htm' % year)\n",
    "        soup = bs(response.text,'html.parser')\n",
    "\n",
    "        # Find location of necessary data in soup object\n",
    "        soup_tables = soup.find_all('table')\n",
    "        soup_elements = soup_tables[3].find_all('td')\n",
    "\n",
    "        # For each td element, find and store data in a list \n",
    "        movie_data=[]\n",
    "        \n",
    "        for i in soup_elements:\n",
    "            if i.find('a')!=None:\n",
    "                movie_data.append(i.find('a').contents[0]) \n",
    "            elif i.find('font')!=None:\n",
    "                movie_data.append(i.find('font').contents[0])\n",
    "            elif i.find('b')!=None:\n",
    "                movie_dataappend(i.find('b').contents[0])\n",
    "\n",
    "        ### Clean Data:\n",
    "        \n",
    "        # Remove extraneous tags\n",
    "        movie_data = [a.contents[0] if type(a)!=bs4.element.NavigableString else a for a in movie_data]\n",
    "\n",
    "        # Strip special characters\n",
    "        movie_data = [re.sub('[^A-Za-z0-9-. ]+', '', a) for a in movie_data]\n",
    "\n",
    "        # Fill NaNs\n",
    "        movie_data = [np.nan if a =='na' else a for a in movie_data]\n",
    "        \n",
    "        # Set first 6 elements as column headers\n",
    "        to_df = movie_data[6:]\n",
    "\n",
    "        # Define the column names \n",
    "        columns = ['rank','title','studio','worldwide-gross','domestic-gross','domestic-pct','overseas-gross','overseas-pct']\n",
    "\n",
    "        # Convert to dataframe\n",
    "        nrow = int(len(to_df)/len(columns)) \n",
    "        dirty_movies_df = pd.DataFrame(np.array(to_df).reshape(nrow,8),columns=columns)\n",
    "        \n",
    "        # Remove unnecessary columns\n",
    "        dirty_movies_df = dirty_movies_df.iloc[: , 0:3]\n",
    "        dirty_movies_df[\"rank\"] = dirty_movies_df[\"rank\"].apply(int)\n",
    "        dirty_movies_df = dirty_movies_df.loc[dirty_movies_df[\"rank\"] <=10,:]\n",
    "        \n",
    "        # Add year column to dataframe\n",
    "        dirty_movies_df['year']=int(year)\n",
    "        \n",
    "        # Add dataframe for specified year to list of dataframes for all years\n",
    "        movie_df_list.append(dirty_movies_df)\n",
    "        \n",
    "    # Convert list of dataframes to single dataframe\n",
    "    movie_df = pd.concat(movie_df_list)\n",
    "    movie_dicts = movie_df.to_dict(orient='records') \n",
    "    \n",
    "    return (movie_dicts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Billboard Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chart(data, year):\n",
    "    \n",
    "    \"\"\" Use the Python package for parsing HTML.  Calls and receives HTML as strings to process for artists.\"\"\"\n",
    "    \n",
    "    # Create soup object to parse the html\n",
    "    soup = bs(data,\"html5lib\")\n",
    "    \n",
    "    # Create a list to return\n",
    "    list_albums = []\n",
    "\n",
    "    # Inspect parsed html\n",
    "    # For each article item, loop and identify tags to extract from.\n",
    "    # For each entry, add a dictionary to the album list\n",
    "    \n",
    "    for item in soup.select('article'):\n",
    "        rank = int(item.select_one(\".ye-chart-item__rank\").string.strip())\n",
    "        title = item.select_one(\".ye-chart-item__title\").string.strip()\n",
    "        artist = item.select_one(\".ye-chart-item__artist\").text.replace(\"\\n\", \"\")\n",
    "        list_albums.append({'rank':rank, 'title':title, 'artist':artist,' year':year})\n",
    "    \n",
    "    return(list_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def album_scraper():\n",
    "\n",
    "    \"\"\"Scrapes https://www.billboard for the top ten albums for 2008-2018 based on gross box-office amount.\n",
    "    Returns a list of dictionaries with year, album title, and artist name\"\"\"\n",
    "\n",
    "    # Create a list of years we are querying data for\n",
    "    years = [str(a) for a in range(2008,2019)]\n",
    "    \n",
    "    all_albums = []\n",
    "\n",
    "    # For each year, use requests library to get HTML and parse contentus using process_chart function\n",
    "    # Add newly created list of dictionaries for specified year to comprehensive list for all years\n",
    "    for year in years:\n",
    "        url = requests.get(\"https://www.billboard.com/charts/year-end/\"+str(year)+\"/top-billboard-200-albums\")\n",
    "        data = url.content\n",
    "        all_albums = all_albums + process_chart(data,year)\n",
    "    \n",
    "    # Filter just the top 10 albums for each year and insert into final list of dictionaries\n",
    "    album_dicts = []\n",
    "    for album in all_albums:\n",
    "        if (album[\"rank\"] < 11):\n",
    "            top_ten.append(album)\n",
    "    \n",
    "    return(album_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_movie_scraper(movie_dict):\n",
    "\n",
    "    \"\"\"Adds review information from metacritic.com to provided movie dictionary\n",
    "    Returns a dictionary with year, rank, movie title, user rating, and number of reviewers\"\"\"\n",
    "    \n",
    "    ## INSERT CODE HERE\n",
    "    ## GRETEL - MAKE SURE TO REMOVE THE EXECUTABLE PATH ASSIGNMENT\n",
    "    \n",
    "    return(meta_movie_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacritic_album_scraper(album_dict):\n",
    "\n",
    "    \"\"\"Adds review information from metacritic.com to provided album dictionary\n",
    "    Returns a dictionary with year, rank, album title, artist name, user rating, and number of reviewers\"\"\"\n",
    "    \n",
    "    ## INSERT CODE HERE\n",
    "    ## GRETEL - MAKE SURE TO REMOVE THE EXECUTABLE PATH ASSIGNMENT\n",
    "    \n",
    "    return(meta_album_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of dictionaries for top movies and music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_list and movie_list, both lists of dictionary, to enter into mongo database\n",
    "# GRETEL - FIGURE OUT EXACTLY HOW THIS WORKS BASED ON WHAT IS RETURNED AT WHAT POINT\n",
    "# IT WOULD BE IDEAL FOR US TO END UP WITH A LIST OF DICTIONARIES FOR EACH MOVIE_DICT_LIST AND MUSIC_DICT_LIST\n",
    "\n",
    "## UPDATE CODE AS APPROPRIATE BASED ON SOURCE CODE FROM OTHER SCRIPTS\n",
    "\n",
    "# Scrape BoxOfficeMojo and Billboard Music for a list of dictionaries of the top 10 movies for 2008-2018\n",
    "movie_BOM_dict_list = movie_scraper()\n",
    "album_Bill_dict_list = album_scraper()\n",
    "\n",
    "# Add review information from Metacritic to new list of dictionaries for top movies\n",
    "movie_dict_list = []\n",
    "for movie_dict in movie_BOM_dict_list:\n",
    "    movie_dict_list.append(metacritic_movie_scraper(movie_dict))\n",
    "\n",
    "# Add review information from Metacritic to new list of dictionaries for top music albums\n",
    "album_dict_list = []\n",
    "for album_dict in album_Bill_dict_list:\n",
    "    album_dict_list.append(metacritic_music_scraper(album_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to mongo using pymongo to create local database\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Create Top 10 database\n",
    "db = client.top_10_db\n",
    "\n",
    "# Create movies and albums collections\n",
    "movies = db.movies\n",
    "albums = db.albums\n",
    "\n",
    "# Insert top 10 movies and albums for 2008-2018\n",
    "# GRETEL - FIGURE OUT WHETHER WE WANT TO UPSERT\n",
    "db.movies.insert_many(movie_dict_list)\n",
    "db.albums.insert_many(album_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
