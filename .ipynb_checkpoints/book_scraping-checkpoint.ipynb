{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_scraper(url):\n",
    "    \n",
    "    \"\"\"Scrapes given Amazon url for the book review information.\n",
    "    Returns a dictionary with full title, boolean indicating if reviews are available, \n",
    "    and review number and rating if so. If reviews are not available, review number and rating are set to None.\n",
    "    \n",
    "    N.B. Must use splinter as requests returns a 504 error\"\"\"\n",
    "    \n",
    "    # Open Amazon book url using Splinter  \n",
    "    # For MAC Users\n",
    "    #executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    # For Windows Users\n",
    "    executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "    with Browser(\"chrome\", **executable_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "\n",
    "        # Create Beautiful soup object\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "        \n",
    "        # Get full title\n",
    "        title = soup.find(\"span\", id=\"ebooksProductTitle\").text.replace(\"\\n\",\"\").replace(\"  \", \"\")\n",
    "        \n",
    "        # Determine if Review information is available. \n",
    "        # If not, set rev_available to False and enter None for review information\n",
    "        # If yes, set rev_available to True and enter review information\n",
    "        rev_count_string = soup.find(\"span\", id=\"acrCustomerReviewText\")\n",
    "        if (rev_count_string == None):\n",
    "            rev_available = False\n",
    "            rev_count = None\n",
    "            rev_avg = None\n",
    "        else:\n",
    "            rev_available = True\n",
    "            rev_count = int(rev_count_string.text.split(\" \")[0].replace(\",\", \"\"))\n",
    "            rev_avg_string = soup.find(\"span\", class_=\"arp-rating-out-of-text a-color-base\").text\n",
    "            rev_avg = float(rev_avg_string.split(\" \")[0])\n",
    "            \n",
    "        # Return dictionary of book information\n",
    "        book_dict = {\"title\": title, \"rev_available\": rev_available, \"rev_count\": rev_count, \"rev_avg\": rev_avg}\n",
    "        return(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def az_scraper(x):\n",
    "\n",
    "    \"\"\"Scrapes Amazon.com website for the book rated x on the Amazon Top 50 \n",
    "    best selling paid ebooks, updated hourly.\n",
    "    Returns dictionary of book information with title, primary author, amazon book url, \n",
    "    whether reviews are available, total number of reviews, a review score, and link to book image\"\"\"\n",
    "    \n",
    "    # Set rank of book\n",
    "    rank = x+1\n",
    "    \n",
    "    # Use requests to get HTML from amazon\n",
    "    url = 'https://www.amazon.com/Best-Sellers-Kindle-Store-eBooks/zgbs/digital-text/154606011/ref=zg_bs_unv_kstore_2_3511261011_1'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "\n",
    "    # Create Beautiful soup object\n",
    "    soup = bs(content, \"html.parser\")\n",
    "\n",
    "    # Create Beautiful soup object for specified book\n",
    "    book_soup = soup.find_all(\"span\", class_=\"aok-inline-block zg-item\")[x]\n",
    "\n",
    "    # Get book author (note: only primary author is listed)\n",
    "\n",
    "    try:\n",
    "        author = book_soup.find(\"a\", class_=\"a-size-small a-link-child\").text\n",
    "    except AttributeError:\n",
    "        author = book_soup.find(\"div\", class_=\"a-row a-size-small\").find(\"span\").text\n",
    "\n",
    "    # Get book url\n",
    "    book_href = book_soup.find(\"a\")[\"href\"]\n",
    "    url = f\"https://www.amazon.com{book_href}\"\n",
    "\n",
    "    # Get URL for book image\n",
    "    img_url = book_soup.find(\"img\")[\"src\"]\n",
    "\n",
    "    # Return dictionary of book information\n",
    "    book_dict = {**book_scraper(url), **{\"rank\": rank, \"author\": author, \"url\": url, \"img_url\": img_url}}\n",
    "    return(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_book_scraper():\n",
    "\n",
    "    \"\"\"Scrapes Amazon.com website for top 10 bestselling paid ebooks, updated hourly. \n",
    "    Creates collection \"books\" in top 10 database with title, primary author, amazon url, \n",
    "    whether reviews are available, total number of reviews, review score, \n",
    "    and link to book image for each book\n",
    "    \n",
    "    Notes: Includes pre-orders which mostly do not have reviews.\n",
    "    Includes only primary author if book has multiple authors\"\"\"\n",
    "\n",
    "    # Connect to mongo\n",
    "    conn = 'mongodb://localhost:27017'\n",
    "    client = pymongo.MongoClient(conn)\n",
    "\n",
    "    # Connect to Top 10 database\n",
    "    db = client.top_10_db\n",
    "    \n",
    "    # If collection books exists, drop it so the new top 10 information will replace it\n",
    "    db.books.drop()\n",
    "    \n",
    "    #Create new empty books collection\n",
    "    books = db.books\n",
    "    \n",
    "    # Insert top 10 books into database\n",
    "    for x in range(10):\n",
    "        db.books.insert_one(az_scraper(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_book_scraper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
