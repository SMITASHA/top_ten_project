{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best-sellers:\n",
    "https://www.amazon.com/Best-Sellers-Kindle-Store-eBooks/zgbs/digital-text/154606011/ref=zg_bs_unv_kstore_2_3511261011_1\n",
    "\n",
    "Notes:\n",
    "\n",
    "Think about where we want exceptions\n",
    "Make sure to note how we are futzing with data and what we're doing with the exception handling\n",
    "\n",
    "The problem right now is that with the best-selling, they include some pre-orders, which don't have reviews\n",
    "\n",
    "We could skip these or we could do a different scrape with this query:\n",
    "\n",
    "https://www.amazon.com/s?i=digital-text&rh=n%3A133140011%2Cn%3A133141011%2Cn%3A154606011%2Cn%3A3511261011&s=featured-rank&lo=list&qid=1556572094&ref=sr_pg_1\n",
    "\n",
    "That's ya and teen sorted by \"featured\"\n",
    "\n",
    "# NOTE - AZ only lists a single author\n",
    "\n",
    "Gotta reiterate how to think about query errors\n",
    "\n",
    "Think about how to handle review text\n",
    "\n",
    "We can also include a link to the book image\n",
    "\n",
    "We can also get a bunch of numbers from GR and AZ and compare them?\n",
    "\n",
    "Note - it will truncate the title if it's long\n",
    "\n",
    "The GR part doesn't work for all titles; Not sure where it fails\n",
    "\n",
    "Note: the az list is only for paid ebooks\n",
    "\n",
    "note: it would be technically better to do the top 100, but it's a PITA\n",
    "\n",
    "There's something wrong with the indices we are using for testing. I think it should fail b/c I'm passing x-1, but it's not. Check the range thing\n",
    "\n",
    "Figure out what the F is going on with https://www.amazon.com/Harley-Merlin-Stolen-Magicals-ebook/dp/B07HLKV538/ref=zg_bs_3511261011_40?_encoding=UTF8&psc=1&refRID=M0EFSTR4YYGK220B34QW\n",
    "\n",
    "so far, it doesn't work for 40-45\n",
    "works for 46\n",
    "\n",
    "50 doesn't work --> fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "import random\n",
    "from api_keys import key\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib.parse as UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    \"\"\"Initializes a splinter Browser object\"\"\"\n",
    "    \n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_scraper(url):\n",
    "    \n",
    "    \"\"\"Scrapes given Amazon url for the book review information.\n",
    "    Returns a dictionary with full title, whether reviews are available, and review information if so\"\"\"\n",
    "    \n",
    "    # Open Amazon book url using Splinter\n",
    "    with init_browser() as browser:\n",
    "        browser.visit(url)\n",
    "\n",
    "        # Create Beautiful soup object\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "        \n",
    "        # Get full title\n",
    "        title = soup.find(\"span\", id=\"ebooksProductTitle\").text.replace(\"\\n\",\"\").replace(\"  \", \"\")\n",
    "        \n",
    "        # Determine if Review information is available. \n",
    "        # If not, set rev_available to false and enter None for review information\n",
    "        # If yes, set rev_available to true and enter review information\n",
    "        rev_count_string = soup.find(\"span\", id=\"acrCustomerReviewText\")\n",
    "        asin = soup.find()\n",
    "\n",
    "        if (rev_count_string == None):\n",
    "            rev_available = False\n",
    "            rev_count = None\n",
    "            rev_score = None\n",
    "            rev_top = None\n",
    "        else:\n",
    "            rev_available = True\n",
    "            rev_count = int(rev_count_string.text.split(\" \")[0].replace(\",\", \"\"))\n",
    "            rev_score_string = soup.find(\"span\", class_=\"arp-rating-out-of-text a-color-base\").text\n",
    "            rev_score = float(rev_score_string.split(\" \")[0])\n",
    "            rev_top = soup.find(\"div\", class_=\"a-expander-content reviewText review-text-content a-expander-partial-collapse-content\").text\n",
    "\n",
    "        \n",
    "        book_dict = {\"Title\": title, \"Amazon Reviews Available\": rev_available, \"Total Amazon Reviews\": rev_count, \"Average Amazon Rating\": rev_score, \"Top Review\": rev_top}\n",
    "        return(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def az_scraper(x):\n",
    "\n",
    "    \"\"\"Scrapes Amazon.com website for the book rated x on the Amazon Top 50 \n",
    "    best selling paid young adult and teen books list.\n",
    "    Returns a dictionary with Title, Author, Amazon book url, total number or reviews, a review score, \n",
    "    and the text of the top review\"\"\"\n",
    "    \n",
    "    # Open Amazon using Splinter\n",
    "    with init_browser() as browser:\n",
    "        \n",
    "        url = 'https://www.amazon.com/Best-Sellers-Kindle-Store-eBooks/zgbs/digital-text/154606011/ref=zg_bs_unv_kstore_2_3511261011_1'\n",
    "        browser.visit(url)\n",
    "\n",
    "        # Create Beautiful soup object\n",
    "        soup = bs(browser.html, \"html.parser\")\n",
    "        \n",
    "        # Create Beautiful soup object for specified book\n",
    "        book_soup = soup.find_all(\"span\", class_=\"aok-inline-block zg-item\")[x]\n",
    "        \n",
    "        # Get Best Selling Book author\n",
    "        \n",
    "        try:\n",
    "            book_author = book_soup.find(\"a\", class_=\"a-size-small a-link-child\").text\n",
    "        except AttributeError:\n",
    "            book_author = book_soup.find(\"div\", class_=\"a-row a-size-small\").find(\"span\").text\n",
    "        \n",
    "        # Get Best Selling Book link\n",
    "        book_href = book_soup.find(\"a\")[\"href\"]\n",
    "        book_url = f\"https://www.amazon.com{book_href}\"\n",
    "        \n",
    "        # Get URL for book image\n",
    "        book_img = book_soup.find(\"img\")[\"src\"]\n",
    "        \n",
    "        # Return dictionary of book information\n",
    "        book_dict = {**book_scraper(book_url), **{\"Author\": book_author, \"Url\": book_url, \"Book Image\": book_img}}\n",
    "\n",
    "    return(book_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Goodreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_query(title):\n",
    "\n",
    "    \"\"\"Queries Goodreads API for a given book title.\n",
    "    Returns a dictionary with whether GoodReads review information is available,\n",
    "    number of GoodReads ratings, and average Goodreads rating\"\"\"\n",
    "    \n",
    "    # Set base API url\n",
    "    url = \"https://www.goodreads.com/book/title.xml?\"\n",
    "\n",
    "    # Encode title for url query\n",
    "    title_query = UP.quote_plus(title)\n",
    "    \n",
    "    # Compose query url\n",
    "    query_url = f\"https://www.goodreads.com/book/title.xml?&key={key}&title={title_query}\"\n",
    "    \n",
    "    # Query GoodReads API\n",
    "    response = requests.get(query_url)\n",
    "    \n",
    "    if (response.status_code != requests.codes.ok):\n",
    "        return({\"GoodReads Available\": False, \"Number of GoodReads Ratings\": None, \"Average GoodReads Rating\": None})\n",
    "    else:\n",
    "        # Parse XML from response object\n",
    "        root = ET.fromstring(response.content)\n",
    "        for count in root.findall(\"./book/work/ratings_count\"):\n",
    "            ratings_count = int(count.text)\n",
    "        for average in root.findall(\"./book/average_rating\"):\n",
    "            rating_average = float(average.text)\n",
    "\n",
    "        # Return dictionary of GoodReads rating information\n",
    "        gr_dict = {\"GoodReads Available\": True, \"Number of GoodReads Ratings\": ratings_count, \"Average GoodReads Rating\": rating_average}\n",
    "        return(gr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_book(x):\n",
    "\n",
    "    \"\"\"Scrapes Amazon.com website and queries Goodreads API for the \n",
    "    book rated x on the Amazon Top 50 best selling paid young adult and teen books list.\n",
    "    Returns a dictionary Amazon and GoodReads information\"\"\"\n",
    "    \n",
    "    # Scrape Amazon for book information\n",
    "    az_dict = az_scraper(x-1)\n",
    "    \n",
    "    # Extract title from dictionary for use in GoodReads query\n",
    "    title = az_dict[\"Title\"]\n",
    "    \n",
    "    # Query GoodReads API for book information\n",
    "    gr_dict = gr_query(title)\n",
    "    \n",
    "    # Return dictionary of book information\n",
    "    book_dict = {**az_dict, **gr_dict}\n",
    "    return(book_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This produces a dictionary of book information for the a random book in the top 50 best selling YA books on amazon\n",
    "# x = random.randint(1,51)\n",
    "# book_dict = ya_book(x)\n",
    "# print(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'Cold Waters (Normal, Alabama Book 1)',\n",
       " 'Amazon Reviews Available': True,\n",
       " 'Total Amazon Reviews': 485,\n",
       " 'Average Amazon Rating': 4.2,\n",
       " 'Top Review': '‘Cold Waters’ was my Amazon First Read choice for April as I love psychological thrillers and I was not disappointed as this was definitely a page turner. Author Debbie Herbert is new to me, however has created a thrilling story of murder and madness set around the dark and cold waters of Alabama.After a summer-night swim 14 year old Violet is found confused, wandering in the forest—and her best friend Ainsley has disappeared. Everyone is accusing Violet of murder however without a body, murder charges won’t stick, yet Violet is sent away to an institution.The story picks up when she returns 10 years later and goes back and forth between that tragic night and the present day - sort of flashback like but mainly her trying to piece things together as she has no solid memory of what happened that night yet it has wreaked havoc on her mental health.On the edge of madness, Violet must fight to keep her sanity long enough for the terrible truth to float up from the ‘cold waters’.By the end of the book many mysteries are revealed, and the reader is left spinning. Debbie Herbert is a new author to me however it is clear she is a master at detailed, vivid description of the landscape and characters It is definitely a psychological thriller in it’s most nightmarish form. Highly recommended. 4.5 StarsI am a verified purchaser in Australia\\n',\n",
       " 'Author': 'Debbie Herbert',\n",
       " 'Url': 'https://www.amazon.com/Cold-Waters-Normal-Alabama-Book-ebook/dp/B07HF4SCB7/ref=zg_bs_154606011_1/142-9925279-5692121?_encoding=UTF8&psc=1&refRID=76DC0H6NF9QX0DKV708W',\n",
       " 'Book Image': 'https://images-na.ssl-images-amazon.com/images/I/91PBRWt1fML.__BG0,0,0,0_FMpng_AC_UL200_SR200,200_.jpg',\n",
       " 'GoodReads Available': False,\n",
       " 'Number of GoodReads Ratings': None,\n",
       " 'Average GoodReads Rating': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_book(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of the top 10 books\n",
    "top_10 = []\n",
    "\n",
    "for x in range(10):\n",
    "    top_10.append(ya_book(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_10 = []\n",
    "\n",
    "for x in range(10, 20):\n",
    "    next_10.append(ya_book(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "again_10 = []\n",
    "\n",
    "for x in range(20, 30):\n",
    "    again_10.append(ya_book(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_10 = []\n",
    "\n",
    "for x in range(30,40):\n",
    "    pu_10.append(ya_book(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-07a4c1d6d13e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-1c90f9f496fb>\u001b[0m in \u001b[0;36mya_book\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Scrape Amazon for book information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maz_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maz_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Extract title from dictionary for use in GoodReads query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-97f47eccbdd3>\u001b[0m in \u001b[0;36maz_scraper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Return dictionary of book information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mbook_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbook_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Author\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbook_author\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Url\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbook_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Book Image\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbook_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-edad84c735a1>\u001b[0m in \u001b[0;36mbook_scraper\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Get full title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ebooksProductTitle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Determine if Review information is available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# This is what needs to be tested\n",
    "f_10 = []\n",
    "\n",
    "for x in range(41,51):\n",
    "    f_10.append(ya_book(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ya_book(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': \"The Governess (Ladies of Miss Bell's Finishing School Book 1)\", 'Amazon Reviews Available': True, 'Total Amazon Reviews': 23, 'Average Amazon Rating': 4.6, 'Top Review': \"The characters are very, very briefly mentioned in On My Honor A Brethren in Arms series. It was a delightful read as we met the four young women but this story focused on Adelaide. Still worried about Adelaide's brother by end of the story but I'm sure his storyline will be in the other series.  Can't wait for book 2.\\n\", 'Author': 'Elizabeth Johns', 'Url': 'https://www.amazon.com/Governess-Ladies-Bells-Finishing-School-ebook/dp/B07NSPMBMH/ref=zg_bs_3511261011_50/145-3567204-9682019?_encoding=UTF8&psc=1&refRID=SF1MVCBDYW1EKD1N0W9V', 'Book Image': 'https://images-na.ssl-images-amazon.com/images/I/81cWaavKnUL._UX300_PJku-sticker-v7,TopRight,0,-50_OU01__BG0,0,0,0_FMpng_AC_UL200_SR200,200_.jpg', 'GoodReads Available': False, 'Number of GoodReads Ratings': None, 'Average GoodReads Rating': None}\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'The Paper Magician (The Paper Magician Series, Book 1)', 'Amazon Reviews Available': True, 'Total Amazon Reviews': 4489, 'Average Amazon Rating': 4.0, 'Top Review': 'Not every recommendation is a smash hit.I don\\'t feel bad about reading \"The Paper Magician.\" It\\'s not a bad book. It\\'s not a great book. Mostly what I really feel after finishing \"The Paper Magician\" is disappointment. Not a lot mind you, but enough that I wish Holmberg had done a slightly better job.Holmberg does have a good introduction. It did not take more than a couple words for me to be whisked away into this new world seeking out adventure and excitement. The first several chapters kept my anticipation levels high as everything started clicking together and I could start to see the outline of something great. Next thing I know, it happened - the great catalyst that sends a story screeching out to the wild blue where heroes are made, and villains are ended. \"This is it!\" I thought as Ceony is thrust into the start of her adventure - and then the rest of the book is spent with the heroine literally flailing around in her mentors memories and emotions.The previous reading experience that keeps floating through my head as I try to wrap my thoughts around what kept this book from being \"great\" is camping. Camping is a lot of fun (or can be), but when read in \"Harry Potter and the Deathly Hallows\" it dragged the story to a slow crawl. The same holds true when Ceony goes \"camping\" (figuratively, not literally) in her adventure. Instead of growing and making her own story, we spend endless chapters learning about Thane\\'s past. Without looking it up, my recollection is that more than half the book is spent flailing (literally, not figuratively) around in events that have little to no impact to the actual outcome of the story, or growth of the main character other than falling in love with the first person who has been \"nice\" to her.Again, this is not a bad book. Three stars is not horrible, but there is definatly much room for improvement in my opinion. I was interested in reading the second book in the series to see if things improve any for Ceony\\'s story, but the reviews already written for that book lead me to believe that is not the case. I will be spending my money elsewhere for now, but I\\'ll keep Holmberg in mind next time I don\\'t have anything already high up on my reading wishlist.\\n', 'Author': 'Charlie N. Holmberg', 'Url': 'https://www.amazon.com/Paper-Magician-Book-ebook/dp/B00HVF7OL0/ref=zg_bs_3511261011_46/147-0268586-0001957?_encoding=UTF8&psc=1&refRID=3GB7BPT74H6JRKSKMGA7', 'Book Image': 'https://images-na.ssl-images-amazon.com/images/I/81PkxfMcfaL._UX300_PJku-sticker-v7,TopRight,0,-50_OU01__BG0,0,0,0_FMpng_AC_UL200_SR200,200_.jpg', 'GoodReads Available': True, 'Number of GoodReads Ratings': 56959, 'Average GoodReads Rating': 3.64}\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.com/Harley-Merlin-Stolen-Magicals-ebook/dp/B07HLKV538/ref=zg_bs_3511261011_40?_encoding=UTF8&psc=1&refRID=M0EFSTR4YYGK220B34QW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with init_browser() as browser:\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Create Beautiful soup object\n",
    "    soup = bs(browser.html, \"html.parser\")\n",
    "    x = soup.find(\"div\", class_=\"a-section a-spacing-none\")\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full title\n",
    "title = soup.find(\"span\", id=\"ebooksProductTitle\").text.replace(\"\\n\",\"\").replace(\"  \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = soup.find(\"div\", class_=\"a-section a-spacing-none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = az_scraper(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'One Word Kill (Impossible Times Book 1)', 'Amazon Reviews Available': True, 'Total Amazon Reviews': 191, 'Average Amazon Rating': 4.3, 'Top Review': \"I almost skipped this book because of the title, but the synopsis didn't match it so I gambled on it. I was 80% right. Nick, our 15 year old protagonist, has just found out he has leukemia and immediately starts chemo. He is a math genius and less comfortable socially. He does have a crew, though, his Dungeons and Dragons game group that meets weekly. They come from both sides of the tracks and Nick is more in the middle. A girl has recently joined the mix. We are given stream of consciousness insight into Nick’s mind. This is very well done. You feel the adolescent determination, scattered thoughts, and tendency to jump into situations without thinking through possible consequences. D&D plays heavily into the story and things in the game start to mysteriously mirror real life. There is a time travel element that drives the plot. Without saying too much, I really enjoyed the story as a light read until it got much darker with real life drug dealers, violence, and death. It's almost like two different books. The story could have gone a different direction, keeping the main elements while staying less serious and graphic, and it would be a much better read. There are expletives and profanity sprinkled throughout.\\n\", 'Author': 'Mark Lawrence', 'Url': 'https://www.amazon.com/Word-Kill-Impossible-Times-Book-ebook/dp/B07C24V3SD/ref=zg_bs_3511261011_1/142-8357475-7795152?_encoding=UTF8&psc=1&refRID=4YFYJWFJQMDJB2HWJHQ9', 'Book Image': 'https://images-na.ssl-images-amazon.com/images/I/814WbQdna7L.__BG0,0,0,0_FMpng_AC_UL200_SR200,200_.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
